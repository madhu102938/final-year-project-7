{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88178997-5ec0-4aab-8069-977e95ba6ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92662984-e819-49c5-9909-627b03052486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tripti/FYP_2024'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b976f28d-0130-4636-85b0-01b528ce5ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/tripti/miniconda3/envs/tensorflow/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/tripti/.local/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/tripti/.local/lib/python3.10/site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/tripti/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/tripti/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/tripti/.local/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a1d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f15389c3-6619-42a8-ac0a-e6c87c8598a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/tripti/miniconda3/envs/tensorflow/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/tripti/.local/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/tripti/.local/lib/python3.10/site-packages (from tensorflow) (5.28.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/tripti/.local/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /home/tripti/.local/lib/python3.10/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/tripti/.local/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/tripti/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /home/tripti/.local/lib/python3.10/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/tripti/.local/lib/python3.10/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /home/tripti/.local/lib/python3.10/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/tripti/.local/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/tripti/.local/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/tripti/.local/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/tripti/.local/lib/python3.10/site-packages (from tensorflow) (1.68.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/tripti/.local/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/tripti/.local/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/tripti/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/tripti/.local/lib/python3.10/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/tripti/.local/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: rich in /home/tripti/.local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /home/tripti/.local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/tripti/.local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/tripti/.local/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/tripti/.local/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/tripti/.local/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/tripti/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/tripti/.local/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/tripti/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "971c2aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 16:49:08.601198: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-27 16:49:08.620428: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732706348.642737   15769 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732706348.649158   15769 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-27 16:49:08.672080: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, optimizers, Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80939d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_MCI_Features_file_path = r'./feature_extraction/MCI_final_features_all_1.pkl'\n",
    "with open(pickle_MCI_Features_file_path, 'rb') as file:\n",
    "    MCI_funct_features = pickle.load(file)\n",
    "MCI_funct_features.shape\n",
    "MCI_funct_features = np.array(MCI_funct_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c813465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 13456)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCI_funct_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee3a6fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_MCI_Features_file_path = r'feature_extraction/cat12_structural_features.pkl'\n",
    "with open(pickle_MCI_Features_file_path, 'rb') as file:\n",
    "    MCI_Struct_features = pickle.load(file)\n",
    "MCI_Struct_features.shape\n",
    "MCI_Struct_features = np.array(MCI_Struct_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9886dee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 169, 205, 169)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCI_Struct_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53ad34c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "structural_features loaded successfully!\n",
      "Shape of loaded array: (40, 169, 205, 169)\n"
     ]
    }
   ],
   "source": [
    "# Define the same file path\n",
    "file_path = r'feature_extraction/Structal_cat_fpickle.pkl'\n",
    "\n",
    "# Load the NumPy array from the file\n",
    "with open(file_path, \"rb\") as file:  # 'rb' means read binary\n",
    "    loaded_structural_features = pickle.load(file)\n",
    "\n",
    "print(\"structural_features loaded successfully!\")\n",
    "print(\"Shape of loaded array:\", loaded_structural_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "959837d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 13456)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_AD_Features_file_path = r\"feature_extraction/func_features_AD.pkl\"\n",
    "with open(pickle_AD_Features_file_path, 'rb') as file:\n",
    "    AD_funct_features = pickle.load(file)\n",
    "AD_funct_features = np.array(AD_funct_features)\n",
    "AD_funct_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "697e6519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 13456)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCI_funct_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9217afde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 169, 205, 169)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCI_Struct_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4526fd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 13456)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AD_funct_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed6ff037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 169, 205, 169)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_structural_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4e4b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data Shapes\n",
    "AD_Struct_features = loaded_structural_features\n",
    "# Labels\n",
    "MCI_labels = np.zeros(53)  # Label 0 for MCI\n",
    "AD_labels = np.ones(40)    # Label 1 for AD\n",
    "\n",
    "# Combine functional and structural features\n",
    "funct_features = np.vstack((MCI_funct_features, AD_funct_features))\n",
    "struct_features = np.vstack((MCI_Struct_features, AD_Struct_features))\n",
    "labels = np.hstack((MCI_labels, AD_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "114b1a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming you have loaded your SMRI data into variables\n",
    "# MCI_Struct_features and AD_Struct_features\n",
    "\n",
    "# Combine MCI and AD structural features\n",
    "SMRI_data = np.concatenate([MCI_Struct_features, AD_Struct_features], axis=0)\n",
    "SMRI_labels = np.concatenate([\n",
    "    np.zeros(len(MCI_Struct_features)),  # Label 0 for MCI\n",
    "    np.ones(len(AD_Struct_features))     # Label 1 for AD\n",
    "], axis=0)\n",
    "\n",
    "# Add a channel dimension\n",
    "SMRI_data = np.expand_dims(SMRI_data, axis=-1)  # Shape becomes (num_samples, 169, 205, 169, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43d2344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have loaded your fMRI data into variables\n",
    "# MCI_funct_features and AD_funct_features\n",
    "\n",
    "# Combine MCI and AD functional features\n",
    "fMRI_data = np.concatenate([MCI_funct_features, AD_funct_features], axis=0)\n",
    "\n",
    "# Reshape and add channel dimension\n",
    "fMRI_data = fMRI_data.reshape(-1, 116, 116)\n",
    "fMRI_data = np.expand_dims(fMRI_data, axis=-1)  # Shape becomes (num_samples, 116, 116, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9a4f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate([\n",
    "    np.zeros(len(MCI_funct_features)),  # Label 0 for MCI\n",
    "    np.ones(len(AD_funct_features))     # Label 1 for AD\n",
    "], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99402c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "794478e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train_3d, X_test_3d, X_train_2d, X_test_2d, y_train, y_test = train_test_split(\n",
    "    SMRI_data,\n",
    "    fMRI_data,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "498c87b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator labels (real images are labeled as 1)\n",
    "real_labels_train = np.ones((X_train_3d.shape[0], 1))\n",
    "real_labels_test = np.ones((X_test_3d.shape[0], 1))\n",
    "\n",
    "# For simplicity, use real labels for reconstructed images\n",
    "disc_targets_3d_train = real_labels_train\n",
    "disc_targets_2d_train = real_labels_train\n",
    "\n",
    "disc_targets_3d_test = real_labels_test\n",
    "disc_targets_2d_test = real_labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aec97d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "\n",
    "def build_encoder_3d(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling3D((2, 2, 2))(x)\n",
    "    x = layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling3D((2, 2, 2))(x)\n",
    "    x = layers.Conv3D(128, (3, 3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    latent = layers.Dense(256, activation='relu')(x)\n",
    "    encoder = Model(inputs, latent, name='encoder_3d')\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "555b5c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder_2d(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    latent = layers.Dense(256, activation='relu')(x)\n",
    "    encoder = Model(inputs, latent, name='encoder_2d')\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0084b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder_3d(latent_dim, output_shape):\n",
    "    latent_inputs = Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(np.prod(output_shape)//8, activation='relu')(latent_inputs)\n",
    "    x = layers.Reshape((output_shape[0]//8, output_shape[1]//8, output_shape[2]//8, 8))(x)\n",
    "    x = layers.Conv3DTranspose(128, (3, 3, 3), strides=2, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv3DTranspose(64, (3, 3, 3), strides=2, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv3DTranspose(32, (3, 3, 3), strides=2, padding='same', activation='relu')(x)\n",
    "    outputs = layers.Conv3DTranspose(1, (3, 3, 3), padding='same', activation='sigmoid')(x)\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder_3d')\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "182bf318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder_2d(latent_dim, output_shape):\n",
    "    latent_inputs = Input(shape=(latent_dim,))\n",
    "    x = layers.Dense((output_shape[0]//4)*(output_shape[1]//4)*64, activation='relu')(latent_inputs)\n",
    "    x = layers.Reshape((output_shape[0]//4, output_shape[1]//4, 64))(x)\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), strides=2, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same', activation='relu')(x)\n",
    "    outputs = layers.Conv2DTranspose(1, (3, 3), padding='same', activation='sigmoid')(x)\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder_2d')\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa84d0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator_3d(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = layers.Conv3D(32, (3, 3, 3), activation='relu')(inputs)\n",
    "    x = layers.MaxPooling3D((2, 2, 2))(x)\n",
    "    x = layers.Conv3D(64, (3, 3, 3), activation='relu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    discriminator = Model(inputs, outputs, name='discriminator_3d')\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b00762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator_2d(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    discriminator = Model(inputs, outputs, name='discriminator_2d')\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "947f1e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(input_dim, num_classes):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = layers.Dense(128, activation='relu')(inputs)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    classifier = Model(inputs, outputs, name='classifier')\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ffb776c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732706409.872513   15769 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 45811 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:4b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The total size of the tensor must be unchanged. Received: input_shape=(np.int64(731875),), target_shape=(21, 25, 21, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m encoder_3d \u001b[38;5;241m=\u001b[39m build_encoder_3d(input_shape_3d)\n\u001b[1;32m      9\u001b[0m encoder_2d \u001b[38;5;241m=\u001b[39m build_encoder_2d(input_shape_2d)\n\u001b[0;32m---> 10\u001b[0m decoder_3d \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_decoder_3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape_3d\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m decoder_2d \u001b[38;5;241m=\u001b[39m build_decoder_2d(latent_dim, input_shape_2d[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     12\u001b[0m discriminator_3d \u001b[38;5;241m=\u001b[39m build_discriminator_3d(input_shape_3d)\n",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m, in \u001b[0;36mbuild_decoder_3d\u001b[0;34m(latent_dim, output_shape)\u001b[0m\n\u001b[1;32m      2\u001b[0m latent_inputs \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(latent_dim,))\n\u001b[1;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(np\u001b[38;5;241m.\u001b[39mprod(output_shape)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m8\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(latent_inputs)\n\u001b[0;32m----> 4\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv3DTranspose(\u001b[38;5;241m128\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[1;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv3DTranspose(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), strides\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/ops/operation_utils.py:302\u001b[0m, in \u001b[0;36mcompute_reshape_output_shape\u001b[0;34m(input_shape, newshape, newshape_arg_name)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unknown_dim_count \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m input_size \u001b[38;5;241m!=\u001b[39m math\u001b[38;5;241m.\u001b[39mprod(newshape):\n\u001b[0;32m--> 302\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    303\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe total size of the tensor must be unchanged. Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnewshape_arg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnewshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m         )\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m newshape\n\u001b[1;32m    308\u001b[0m \u001b[38;5;66;03m# We have one -1 in `newshape`, compute the actual value\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The total size of the tensor must be unchanged. Received: input_shape=(np.int64(731875),), target_shape=(21, 25, 21, 8)"
     ]
    }
   ],
   "source": [
    "# Input shapes\n",
    "input_shape_3d = (169, 205, 169, 1)\n",
    "input_shape_2d = (116, 116, 1)\n",
    "latent_dim = 256\n",
    "num_classes = 2\n",
    "\n",
    "# Build models\n",
    "encoder_3d = build_encoder_3d(input_shape_3d)\n",
    "encoder_2d = build_encoder_2d(input_shape_2d)\n",
    "decoder_3d = build_decoder_3d(latent_dim, input_shape_3d[:-1])\n",
    "decoder_2d = build_decoder_2d(latent_dim, input_shape_2d[:-1])\n",
    "discriminator_3d = build_discriminator_3d(input_shape_3d)\n",
    "discriminator_2d = build_discriminator_2d(input_shape_2d)\n",
    "# Build classifier that accepts concatenated latent vectors\n",
    "classifier = build_classifier(latent_dim * 2, num_classes)\n",
    "\n",
    "# Inputs\n",
    "input_3d = Input(shape=input_shape_3d)\n",
    "input_2d = Input(shape=input_shape_2d)\n",
    "\n",
    "# Encoding\n",
    "latent_3d = encoder_3d(input_3d)\n",
    "latent_2d = encoder_2d(input_2d)\n",
    "\n",
    "# Concatenate the two latent representations\n",
    "combined_latent = layers.Concatenate()([latent_3d, latent_2d])\n",
    "\n",
    "# Decoding\n",
    "reconstructed_3d = decoder_3d(latent_3d)\n",
    "reconstructed_2d = decoder_2d(latent_2d)\n",
    "\n",
    "# Discriminator outputs\n",
    "disc_output_3d = discriminator_3d(reconstructed_3d)\n",
    "disc_output_2d = discriminator_2d(reconstructed_2d)\n",
    "\n",
    "# Get classification output\n",
    "classification_output = classifier(combined_latent)\n",
    "\n",
    "# Define the combined model\n",
    "model = Model(\n",
    "    inputs=[input_3d, input_2d],\n",
    "    outputs=[\n",
    "        reconstructed_3d,\n",
    "        reconstructed_2d,\n",
    "        disc_output_3d,\n",
    "        disc_output_2d,\n",
    "        classification_output\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa41a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss weights\n",
    "lambda_reconstruction = 1.0\n",
    "lambda_adversarial = 0.1\n",
    "lambda_classification = 1.0\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'decoder_3d': 'mse',\n",
    "        'decoder_2d': 'mse',\n",
    "        'discriminator_3d': 'binary_crossentropy',\n",
    "        'discriminator_2d': 'binary_crossentropy',\n",
    "        'classifier': 'sparse_categorical_crossentropy'\n",
    "    },\n",
    "    loss_weights={\n",
    "        'decoder_3d': lambda_reconstruction,\n",
    "        'decoder_2d': lambda_reconstruction,\n",
    "        'discriminator_3d': lambda_adversarial,\n",
    "        'discriminator_2d': lambda_adversarial,\n",
    "        'classifier': lambda_classification\n",
    "    },\n",
    "    metrics={\n",
    "        'classifier': 'accuracy'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bceba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator labels (real images are labeled as 1)\n",
    "real_labels = np.ones((SMRI_data.shape[0], 1))\n",
    "fake_labels = np.zeros((SMRI_data.shape[0], 1))\n",
    "\n",
    "# For simplicity, use real labels for reconstructed images (you can adjust as needed)\n",
    "disc_targets_3d = real_labels\n",
    "disc_targets_2d = real_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb2286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_train_3d, X_train_2d],\n",
    "    {\n",
    "        'decoder_3d': X_train_3d,\n",
    "        'decoder_2d': X_train_2d,\n",
    "        'discriminator_3d': disc_targets_3d_train,\n",
    "        'discriminator_2d': disc_targets_2d_train,\n",
    "        'classifier': y_train\n",
    "    },\n",
    "    epochs=20,\n",
    "    batch_size=8,\n",
    "    validation_data=(\n",
    "        [X_test_3d, X_test_2d],\n",
    "        {\n",
    "            'decoder_3d': X_test_3d,\n",
    "            'decoder_2d': X_test_2d,\n",
    "            'discriminator_3d': disc_targets_3d_test,\n",
    "            'discriminator_2d': disc_targets_2d_test,\n",
    "            'classifier': y_test\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84aa083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classifier accuracy on the test set\n",
    "evaluation = model.evaluate(\n",
    "    [X_test_3d, X_test_2d],\n",
    "    {\n",
    "        'decoder_3d': X_test_3d,\n",
    "        'decoder_2d': X_test_2d,\n",
    "        'discriminator_3d': disc_targets_3d_test,\n",
    "        'discriminator_2d': disc_targets_2d_test,\n",
    "        'classifier': y_test\n",
    "    },\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Get the index of the classification loss and accuracy (depends on the order of outputs)\n",
    "classification_accuracy = evaluation[model.metrics_names.index('classifier_accuracy')]\n",
    "\n",
    "print(f'Classifier Test Accuracy: {classification_accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
